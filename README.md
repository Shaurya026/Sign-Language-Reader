# Sign-Language-Reader  
download model at : [model](https://drive.google.com/file/d/1F5OQ9jLh-SsBnXqWQo0MZqbtjFNv0gTg/view?usp=sharingd) (*you need to ask for access!*)   

This project aims to detect american sign language in real time by using a deep learning implementation to classify each hand sign.
<br>A reference to american sign language is given below for comparison to the working real time demo.<br>
<img src="https://github.com/Shaurya026/Sign-Language-Reader/blob/main/Demo%20Files/Chart.jpg" width=75% height=75% alt="ASL"> 

<br> **DEMO-1** For words like 'c', 'a' and 'b'<br>   

<img src="https://github.com/Shaurya026/Sign-Language-Reader/blob/main/Demo%20Files/video-1.gif" width=50% height=50% alt="D1">   

<br> **DEMO-2** For words like 'h', 'e' and 'r'<br>   
<img src="https://github.com/Shaurya026/Sign-Language-Reader/blob/main/Demo%20Files/video-2.gif" width=50% height=50% alt="D2">   

The classificaiton is pretty good in these conditions shown in these demo's but it is important to note that under certain lightining the model fails to classify any hand sign which needs to be addressed in future. 
> The original dataset reffered is taken from this [kaggle link](https://www.kaggle.com/grassknoted/asl-alphabet)
